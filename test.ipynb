{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss( x, x_hat):\n",
    "    \"\"\"\n",
    "    ADD DOCSTRING!!!\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    loss =F.mse_loss(x, x_hat, reduction='none')\n",
    "    loss = loss.view(batch_size, -1).sum(axis=1)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss2( x, x_hat):\n",
    "    \"\"\"\n",
    "    ADD DOCSTRING!!!\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    loss = nn.MSELoss(reduction='none')(x, x_hat)\n",
    "    loss = loss.view(batch_size, -1).sum(axis=1)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "tensor([[0.2456, 0.6061, 0.6894, 0.3184, 0.2796],\n",
      "        [0.1244, 0.2897, 0.3857, 0.9241, 0.6988],\n",
      "        [0.7230, 0.8719, 0.5641, 0.9822, 0.1038],\n",
      "        [0.7798, 0.0593, 0.2094, 0.4049, 0.1569]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((4,5), requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "x_hat = torch.rand_like(x)\n",
    "print(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1: 1.814831256866455 loss2: 1.814831256866455\n"
     ]
    }
   ],
   "source": [
    "loss1 = recon_loss(x, x_hat)\n",
    "loss2 = recon_loss2(x, x_hat)\n",
    "\n",
    "print(f\"loss1: {loss1} loss2: {loss2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8148, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8148, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    \"\"\"\n",
    "    ADD DOCSTRING!!!\n",
    "    \"\"\"\n",
    "    def __call__(self, x, x_hat):\n",
    "        batch_size = x.shape[0]\n",
    "        loss = nn.MSELoss(reduction='none')(x, x_hat)\n",
    "        loss = loss.view(batch_size, -1).sum(axis=1)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8148, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE()(x, x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q = np.array([[0.2267, 0.1953, 0.1735, 0.0688, 0.3356],\n",
    "        [0.2074, 0.2786, 0.1193, 0.2394, 0.1553],\n",
    "        [0.1337, 0.1074, 0.2844, 0.1082, 0.3664]])\n",
    "l = np.array([[ 7.9840,  8.3297, 11.4494],\n",
    "                [6.4572, 5.1127, 6.6388],\n",
    "                [6.1410, 5.3430, 7.9671],\n",
    "                [8.1180, 8.3151, 8.7442],\n",
    "                [8.0247, 7.1036, 8.0665]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.8099728 , 1.72757978, 1.53078478]),\n",
       " array([1.26109116, 1.42439822, 0.71300712]),\n",
       " array([1.0654635 , 0.6374199 , 2.26584324]),\n",
       " array([0.5585184 , 1.99063494, 0.94612244]),\n",
       " array([2.69308932, 1.10318908, 2.9555656 ])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[q[:, i]*l[i] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8099728 , 1.72757978, 1.53078478],\n",
       "       [1.26109116, 1.42439822, 0.71300712],\n",
       "       [1.0654635 , 0.6374199 , 2.26584324],\n",
       "       [0.5585184 , 1.99063494, 0.94612244],\n",
       "       [2.69308932, 1.10318908, 2.9555656 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l * q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.38813518, 6.88322192, 8.41132318])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([q[:, i]*l[i] for i in range(5)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.87813518, 5.31582192, 6.93662318])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([q[:, i]*l[i] for i in range(5)], axis=0) + np.array([-1.5100, -1.5674, -1.4747])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.93662318"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.41132318 - 1.4747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8099728 , 1.72757978, 1.53078478],\n",
       "       [1.26109116, 1.42439822, 0.71300712],\n",
       "       [1.0654635 , 0.6374199 , 2.26584324],\n",
       "       [0.5585184 , 1.99063494, 0.94612244],\n",
       "       [2.69308932, 1.10318908, 2.9555656 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l * q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 4, 4])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch_size = 4\n",
    "k = 5\n",
    "\n",
    "# Example tensor\n",
    "qy = torch.tensor([[5, 4, 2, 3, 1], [5, 4, 3, 2, 1], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\n",
    "y_hat = torch.argmax(qy, dim=-1)  # Indices obtained from y_hat\n",
    "print(y_hat)\n",
    "\n",
    "# Create tensor with 1s at specified indices\n",
    "y_ = torch.zeros(batch_size, k)\n",
    "y_ = torch.scatter(y_, 1, y_hat.unsqueeze(1), 1)\n",
    "\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_ shape: torch.Size([64, 10])\n",
      "y: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]) shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch_size = 64\n",
    "k = 10\n",
    "y_ = torch.zeros([batch_size, k])\n",
    "print(f\"y_ shape: {y_.shape}\")\n",
    "for i in range(k):\n",
    "    y = y_ + torch.eye(k)[i]\n",
    "print(f\"y: {y} shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 3\n",
    "k = 5\n",
    "y_ = torch.zeros([batch_size, k])\n",
    "print(f\"y_ shape: {y_.shape}\")\n",
    "for i in range(k):\n",
    "    y = y_ + torch.eye(k)[i]\n",
    "    print(f\"y: {y} shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2145, 0.2130, 0.3700, 0.0691, 0.1334],\n",
      "        [0.0408, 0.2898, 0.0586, 0.4237, 0.1871],\n",
      "        [0.1669, 0.2629, 0.2627, 0.1270, 0.1805]])\n",
      "tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "xx = torch.nn.Softmax(dim=1)(x)\n",
    "print(xx)\n",
    "print(torch.sum(xx, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "d = \"cpu\"\n",
    "torch.device(\"cuda\" if (torch.cuda.is_available() and d == \"cuda\") else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "l = []\n",
    "x = np.array([1, 2, 3])\n",
    "l.extend(x)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(self, y_true, y_pred):\n",
    "    n_classes = self.k\n",
    "    corrected_pred = np.zeros_like(y_pred)\n",
    "    for cls in range(n_classes):\n",
    "        indx = y_pred == cls\n",
    "        true_cls = np.argmax(np.unique(y_true[indx], return_counts=True))\n",
    "        corrected_pred[indx] = true_cls\n",
    "    acc = np.mean(y_true == corrected_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(self, y_true, y_pred):\n",
    "    n_classes = self.k\n",
    "    corrected_pred = np.zeros_like(y_pred)\n",
    "    for cls in range(n_classes):\n",
    "        indx = y_pred == cls\n",
    "        true_cls = np.argmax(np.unique(y_true[indx], return_counts=True))\n",
    "        corrected_pred[indx] = true_cls\n",
    "    acc = np.mean(y_true == corrected_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_pred, k):\n",
    "    n_classes = k\n",
    "    corrected_pred = np.zeros_like(y_pred)\n",
    "    for cls in range(n_classes):\n",
    "        indx = y_pred == cls\n",
    "        true_cls = np.bincount(y_true[indx]).argmax()\n",
    "        corrected_pred[indx] = true_cls\n",
    "    acc = np.mean(y_true == corrected_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true class: 1\n",
      "cls: 0 corrected: [0 0 1 1 1 1 0 0]\n",
      "true class: 2\n",
      "cls: 1 corrected: [0 0 1 1 1 1 2 2]\n",
      "true class: 0\n",
      "cls: 2 corrected: [0 0 1 1 1 1 2 2]\n",
      "[0 0 0 1 1 1 2 2]\n",
      "[0 0 1 1 1 1 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0, 0, 0, 1, 1, 1, 2, 2])\n",
    "y_pred = np.array([2, 2, 0, 0, 0, 0, 1, 1])\n",
    "\n",
    "get_accuracy(y_true, y_pred, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {1: {'a': [array([1, 1])], 'b': [array([10, 10])]}, 2: {'a': [array([2, 2])], 'b': [array([20, 20])]}})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(dict)\n",
    "ids = [1, 2]\n",
    "out_infer = {\"a\": np.array([[1, 1],[2, 2]]), \"b\": np.array([[10, 10],[20, 20]])}\n",
    "for ind, id in enumerate(ids):\n",
    "    for key in out_infer.keys():\n",
    "        d[id].setdefault(key, []).append(out_infer[key][ind])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms \n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data.shape)\n",
    "print(test_dataset.classes)\n",
    "print(test_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " value: 1 indices: tensor([2, 8])\n",
      " value: 2 indices: tensor([ 1,  7, 11])\n",
      " value: 3 indices: tensor([9])\n",
      " value: 4 indices: tensor([ 3, 10])\n",
      " value: 5 indices: tensor([4])\n",
      " value: 6 indices: tensor([5])\n",
      " value: 7 indices: tensor([ 0,  6, 12])\n",
      "tensor([ 2,  8, 11,  1,  9,  3, 10,  4,  5,  0,  6])\n"
     ]
    }
   ],
   "source": [
    "# Example tensor\n",
    "tensor = torch.tensor([7, 2, 1, 4, 5, 6, 7, 2, 1, 3, 4, 2, 7])\n",
    "\n",
    "# Get unique values and their respective counts\n",
    "unique_values = tensor.unique(return_counts=False)\n",
    "\n",
    "# Initialize a list to store the random indices\n",
    "random_indices = []\n",
    "\n",
    "# Iterate over unique values\n",
    "for value in unique_values:\n",
    "    # Get indices of the current value\n",
    "    indices = torch.where(tensor == value)[0]\n",
    "    print(f\" value: {value} indices: {indices}\")\n",
    "\n",
    "    # Get a random index from the indices\n",
    "    random_index = torch.randperm(len(indices))[:2]\n",
    "    \n",
    "    # Add the random index to the list\n",
    "    random_indices.extend(indices[random_index])\n",
    "\n",
    "# Convert the list to a tensor\n",
    "random_indices_tensor = torch.tensor(random_indices)\n",
    "\n",
    "# Print the random indices\n",
    "print(random_indices_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 4, 5, 6, 7, 2, 1, 3, 4, 2, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {1: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(str, dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"ids_history.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "num_rows = len(data.keys())\n",
    "print(num_rows)\n",
    "num_columns = 3\n",
    "\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_columns ,sharex=False,sharey=False, figsize=(8,10), gridspec_kw={'width_ratios': [3, 1, 1]})\n",
    "def animate_diff(i, data):\n",
    "    ids = list(data.keys())\n",
    "    plots = []\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_columns):\n",
    "            row_id = ids[row]\n",
    "            axs[row, col].clear()\n",
    "            axs[row, 0].set_ylim([0,1])\n",
    "            axs[row, 0].set_xticks(range(0,10))\n",
    "        plots.append(axs[row, 0].bar(range(10), data[row_id][\"qy\"][i]))\n",
    "        plots.append(axs[row, 1].imshow(np.reshape(data[row_id][\"x_true\"], (28,28))))\n",
    "        plots.append(axs[row, 2].imshow(np.reshape(data[row_id][\"x_hat\"][i], (28,28))))\n",
    "    plt.suptitle(f\"Frame {i+1}\")    #plots.append(axs[row, col].imshow(data[i,(row*num_columns)+col,0,:,:21],vmin=(data[i,:,0,:,:21]).min(), vmax=(data[i,:,0,:,:21]).max()))\n",
    "    return plots\n",
    "#print(\"x_gen shape:\", data.shape)\n",
    "ani = FuncAnimation(fig, animate_diff, fargs=[data],  interval=200, blit=False, repeat=True, frames=3)\n",
    "#img_path = save_dir + '/images/'\n",
    "#os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "#ani.save(img_path + f\"gif_ep{ep}_w{w}.gif\", dpi=100, writer=PillowWriter(fps=5))\n",
    "#print('saved image at ' + save_dir + f\"gif_ep{ep}_w{w}.gif\")\n",
    "ani.save(f\"gif_ep.gif\", dpi=100, writer=PillowWriter(fps=5))\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 28 28\n",
      "<class 'list'> 3 10\n"
     ]
    }
   ],
   "source": [
    "k = list(data.keys())\n",
    "d = data[k[0]][\"x_true\"]\n",
    "print(type(d), len(d), len(d[0]))\n",
    "d = data[k[0]][\"x_hat\"]\n",
    "print(type(d), len(d), len(d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"id1\": {\n",
    "        'array1': np.array([[1, 2, 3], [4, 5, 6]]),\n",
    "        'array2': np.array([10, 11, 12])\n",
    "    },\n",
    "    \"id2\": {\n",
    "        'array1': np.array([[1, 2, 3], [4, 5, 6]]),\n",
    "        'array2': np.array([7, 8, 9])\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def history_printer(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print('\\t' * indent + f\"{key}: {type(value)}\")\n",
    "        if isinstance(value, dict):\n",
    "            history_printer(value, indent + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = np.array([1, 2, 3])\n",
    "print(type(l[0]))\n",
    "l = l.astype(np.int32)\n",
    "print(type(l[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
